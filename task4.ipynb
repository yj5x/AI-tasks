{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "name": "task4.ipynb",
      "authorship_tag": "ABX9TyNgFZt2aqRegmMnnQPv9G9E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yj5x/AI-tasks/blob/main/task4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===================\n",
        "#      libraries\n",
        "#====================\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "nr2bdSq6KQ2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===========================\n",
        "#       uploading data\n",
        "#============================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv('/content/drive/MyDrive/AI in business /WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "df = data.copy()\n",
        "\n",
        "# cleaning\n",
        "df.drop('customerID', axis=1, inplace=True)\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "_FEQY7keKQzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CUBK_ur8WdlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#========\n",
        "#  EDA\n",
        "#========\n",
        "\n",
        "# distribution of Churn\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(x='Churn', data=df)\n",
        "plt.title('Churn Distribution')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "df['Churn'].value_counts().plot.pie(autopct='%1.1f%%')\n",
        "plt.title('Churn Ratio')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rw79IBJ9KQv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ajzRpnO_XDJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#=================\n",
        "#   prepare data\n",
        "#=================\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "F941HDIxKQsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#===================\n",
        "#    pretreatment\n",
        "#===================\n",
        "\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numerical_transformer, numerical_features),\n",
        "    ('cat', categorical_transformer, categorical_features)])"
      ],
      "metadata": {
        "id": "wk4zEsFCKQpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#=================================\n",
        "#   training + evaluation models\n",
        "#=================================\n",
        "\n",
        "def train_and_evaluate(model, model_name):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training and Evaluating {model_name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # training\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # prediction\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # evaluation\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nROC Curve:\")\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc_score(y_test, y_proba):.2f}')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.title(f'ROC Curve - {model_name}')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # learning curve\n",
        "    print(\"\\nLearning Curve:\")\n",
        "    train_sizes, train_scores, val_scores = learning_curve(\n",
        "        model, X_train, y_train, cv=5, scoring='accuracy',\n",
        "        train_sizes=np.linspace(0.1, 1.0, 5), n_jobs=-1)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(train_sizes, np.mean(train_scores, 1), 'o-', label='Training Score')\n",
        "    plt.plot(train_sizes, np.mean(val_scores, 1), 'o-', label='Validation Score')\n",
        "    plt.title(f'Learning Curve - {model_name}')\n",
        "    plt.xlabel('Training Examples')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "p2v6UC8mKQm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#==========================\n",
        "#    Logistic Regression\n",
        "#==========================\n",
        "\n",
        "# the model\n",
        "pipeline_lr = Pipeline(steps=[\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('classifier', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "train_and_evaluate(pipeline_lr, \"Logistic Regression\")\n",
        "\n",
        "# with SMOTE\n",
        "smote_pipeline_lr = ImbPipeline(steps=[\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('classifier', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "train_and_evaluate(smote_pipeline_lr, \"Logistic Regression with SMOTE\")\n",
        "\n",
        "# Hyperparameter\n",
        "param_grid_lr = {\n",
        "    'classifier__C': [0.01, 0.1, 1, 10],\n",
        "    'classifier__penalty': ['l2']\n",
        "}\n",
        "grid_lr = GridSearchCV(pipeline_lr, param_grid_lr, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_lr.fit(X_train, y_train)\n",
        "best_lr = grid_lr.best_estimator_\n",
        "train_and_evaluate(best_lr, \"Tuned Logistic Regression\")"
      ],
      "metadata": {
        "id": "akj26AKhKQkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#==========================\n",
        "#      Random Forest\n",
        "#==========================\n",
        "\n",
        "# model\n",
        "pipeline_rf = Pipeline(steps=[\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "train_and_evaluate(pipeline_rf, \"Random Forest\")\n",
        "\n",
        "# SMOTE\n",
        "smote_pipeline_rf = ImbPipeline(steps=[\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "train_and_evaluate(smote_pipeline_rf, \"Random Forest with SMOTE\")\n",
        "\n",
        "# Hyperparameter\n",
        "param_grid_rf = {\n",
        "    'classifier__n_estimators': [100, 200],\n",
        "    'classifier__max_depth': [None, 10]\n",
        "}\n",
        "grid_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "best_rf = grid_rf.best_estimator_\n",
        "train_and_evaluate(best_rf, \"Tuned Random Forest\")"
      ],
      "metadata": {
        "id": "o40IicIcNa6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#==========\n",
        "#   SVM\n",
        "#==========\n",
        "\n",
        "# model\n",
        "pipeline_svc = Pipeline(steps=[\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('classifier', SVC(probability=True, random_state=42))\n",
        "])\n",
        "train_and_evaluate(pipeline_svc, \"SVM\")\n",
        "\n",
        "# SMOTE\n",
        "smote_pipeline_svc = ImbPipeline(steps=[\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('classifier', SVC(probability=True, random_state=42))\n",
        "])\n",
        "train_and_evaluate(smote_pipeline_svc, \"SVM with SMOTE\")\n",
        "\n",
        "# Hyperparameter\n",
        "param_grid_svc = {\n",
        "    'classifier__C': [0.1, 1],\n",
        "    'classifier__kernel': ['linear', 'rbf']\n",
        "}\n",
        "grid_svc = GridSearchCV(pipeline_svc, param_grid_svc, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_svc.fit(X_train, y_train)\n",
        "best_svc = grid_svc.best_estimator_\n",
        "train_and_evaluate(best_svc, \"Tuned SVM\")"
      ],
      "metadata": {
        "id": "z6r6-ba7KQg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#====================\n",
        "# feature selection\n",
        "#====================\n",
        "\n",
        "# pretreatment\n",
        "X_train_processed = preprocessor.fit_transform(X_train, y_train)\n",
        "\n",
        "# feature names\n",
        "processed_feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "# best 10 features\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "selector.fit(X_train_processed, y_train)\n",
        "\n",
        "\n",
        "\n",
        "selected_features = processed_feature_names[selector.get_support()]\n",
        "print(\"Selected Features:\")\n",
        "print(selected_features)"
      ],
      "metadata": {
        "id": "ayeeRVB5KQd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HEhwJZXzKQa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. what is the difference between these plots countplot barplot histplot boxplot and scatterplot and when to use each type\n",
        "\n",
        "countplot: shows how many in each category\n",
        "\n",
        "barplot: shows average per category\n",
        "\n",
        "histplot: shows how numbers are spread\n",
        "\n",
        "boxplot: shows outlier values\n",
        "\n",
        "scatterplot: show relation between two numbers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 2. what step had the biggest impact on model performance\n",
        "\n",
        "i take f1-score as a measure:\n",
        "\n",
        "In logistic the use of pipeline was better\n",
        "\n",
        "In random, pipeline and hypeeparameter were very close in results.\n",
        "\n",
        "In SVM the performance decreased when i used the smote, but with the rest the performance did not change\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 3. how did hyperparameter tuning affect your results\n",
        "\n",
        "In logistic:\n",
        "Increased precision and recall\n",
        "\n",
        "In random:\n",
        "Increased percision\n",
        "but recall decreased\n",
        "\n",
        "In svm:\n",
        "increased percision and recall\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 4. what trade offs did you encounter using pipelines\n",
        "\n",
        "step of  EDA I had to shorten it to make the code easier and avoid repeating processes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 5. how do we detect overfitting and underfitting\n",
        "\n",
        "see if train score is high and test score is low its overfit\n",
        "\n",
        "but if both is low its underfit\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 6. which plots are most useful for analyzing data distribution\n",
        "\n",
        "I think histplot and countplot\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 7. when do we use labelencoder vs onehotencoder  and why\n",
        "\n",
        "labelencoder is for data that has order or can be treated as ordered like (low, medium, high)\n",
        "\n",
        "onehot is for no order like names\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 8. what does random_state do and when should we fix it\n",
        "\n",
        "it control the random steps and we fix it if we want same result every time\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 9. what would change if the data were all floats or all integers\n",
        "\n",
        "the model might not be affected much whether floats or integers, i think what really matters is proper feature scaling to ensure balanced model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 10. which part of the pipeline was most impactful overall\n",
        "\n",
        "Hyperparameter tuning after pipeline impacted performance most\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 11. how can unbalanced data be dealt with and which method did you apply in this project\n",
        "\n",
        "i use smote and it helped to make the data more equal\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 12. did you check for duplicate records how many did you find and what did you do with them\n",
        "\n",
        "yes i check after this question and saw some duplicate rows and i now i have to remove them from data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 13. what is the difference between fit_transform and transform where did you apply each and why\n",
        "\n",
        "fit_transform:\n",
        "I used it on the training data to learn and apply the scaling\n",
        "\n",
        "transform:\n",
        "I used it on the test data to apply the same scaling, so the model doesn’t learn from the test data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 14. what is the difference between  modelpredict and modelpredict_proba in which situations would you use each\n",
        "\n",
        "predict gives the result like 0 or 1, so use it when you just need the result\n",
        "\n",
        "predict_proba show the chance of decision odds before the final result, maybe use it when you want to see how confident the model is\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 15. what was your final best model pipeline and what made it the best\n",
        "\n",
        "it was logistic with Hyperparameter, it give high score and good behavior at learning curve\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 16. how would you approach this task differently in a real world production setting\n",
        "\n",
        "\n",
        "1. clean and prepare data to ensures correct model input  \n",
        "\n",
        "2. use pipelines to keeps steps organized and repeatable  \n",
        "\n",
        "3. monitor predictions of models to catches performance drops early  \n",
        "\n",
        "4. and try to improve the model\n"
      ],
      "metadata": {
        "id": "l4tNJ0M7Zcck"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KFeRAZL1KQX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qKJANQLJ_oU"
      },
      "outputs": [],
      "source": []
    }
  ]
}